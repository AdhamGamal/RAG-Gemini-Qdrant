{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92c2ad8c",
   "metadata": {},
   "source": [
    "# üìò RAG with Qdrant, Google Gemini, and LangChain\n",
    "\n",
    "This project demonstrates how to build a **Retrieval-Augmented Generation (RAG)** pipeline using **LangChain Expression Language (LCEL)**, **Qdrant** as a vector store, and **Google Gemini** as the LLM. It allows you to query knowledge from your own PDF documents, combining **retrieval** and **generation** in a clean, modular pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc7a12",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Load Environment Variables\n",
    "\n",
    "Load the API keys, Qdrant URL, and collection name from the `.env` file to keep secrets secure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9851f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "QDRANT_COLLECTION = os.getenv(\"QDRANT_COLLECTION\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43255ff",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load and Split PDFs\n",
    "\n",
    "Load the PDF documents and split them into chunks for embeddings. This step converts raw PDFs into smaller, manageable text segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13bc63ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Loaded and split 3 PDF(s) into 9 chunks\n"
     ]
    }
   ],
   "source": [
    "from utils.loader import load_and_split_pdfs\n",
    "from utils.embeddings import get_embedding_model\n",
    "from utils.ingest import ingest_documents\n",
    "from utils.retriever import get_retriever, format_docs\n",
    "from utils.llm import get_llm_model\n",
    "from utils.prompt import get_rag_prompt, get_chat_rag_prompt\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# List of PDF files to process\n",
    "PDFS = [\n",
    "    \"data/eldoria_history.pdf\",\n",
    "    \"data/quantum_drive_specs.pdf\",\n",
    "    \"data/zirconia_recipes.pdf\"\n",
    "]\n",
    "\n",
    "# Step 1: Load and split PDFs into chunks\n",
    "docs = load_and_split_pdfs(PDFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf93b0",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Generate Embeddings\n",
    "\n",
    "Use Gemini (or Google) embeddings to convert text chunks into vector representations for retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a05772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize embedding model\n",
    "embedding_model = get_embedding_model(GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c8620b",
   "metadata": {},
   "source": [
    "# 4Ô∏è‚É£ Ingest Documents into Qdrant\n",
    "\n",
    "Store embeddings into Qdrant vector database. Skips ingestion if data already exists unless `force_update=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43908c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è Using existing Qdrant collection 'my_rag_collection'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759346235.862929   16292 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Collection 'my_rag_collection' already has 9 vectors. Skipping ingestion.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_qdrant.qdrant.QdrantVectorStore at 0x71fc5e575640>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Ingest documents into Qdrant vectorstore\n",
    "ingest_documents(QDRANT_URL, QDRANT_API_KEY, QDRANT_COLLECTION, embedding_model, docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3acaee",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Build Retriever and LLM Pipeline\n",
    "\n",
    "Setup the retriever to fetch relevant documents and the LLM to generate answers using a RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "733b69d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è Using existing Qdrant collection 'my_rag_collection'\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Build retriever + LLM\n",
    "retriever = get_retriever(QDRANT_URL, QDRANT_API_KEY, QDRANT_COLLECTION, embedding_model, k=3)\n",
    "llm = get_llm_model(GOOGLE_API_KEY, model=\"models/gemini-flash-latest\")\n",
    "\n",
    "# Step 5: Build prompt template\n",
    "prompt = get_chat_rag_prompt()\n",
    "\n",
    "# Step 6: Build RAG pipeline with LangChain Expressions (LCEL)\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(format_docs),  # retrieve and format docs\n",
    "        \"question\": RunnablePassthrough()  # pass the question as is\n",
    "    }\n",
    "    | prompt  # add the RAG prompt\n",
    "    | llm     # generate the answer\n",
    "    | StrOutputParser()  # parse output to string\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227cbe07",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Test RAG Pipeline\n",
    "\n",
    "Run a few example queries to see how the RAG pipeline generates answers using retrieved documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d64f5149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[QUERY] What led to the fall of the Kingdom of Eldoria?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759346239.242533   16401 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANSWER] The fall of the Kingdom of Eldoria was caused by internal strife among rival noble houses, sparking decades of civil war that drained the nation's strength. This was further destabilized by the rise of the Great Shadow War, where creatures of darkness invaded the borderlands, and the withdrawal of dragons to their mountain strongholds.\n",
      "\n",
      "[QUERY] How does the Starlink Quantum Drive create thrust?\n",
      "[ANSWER] The Starlink Quantum Drive creates a localized warp bubble by manipulating entangled states within the Quantum Resonance Chamber (QRC). Within this bubble, space contracts in front of the ship and expands behind it, propelling the craft forward without traditional thrust.\n",
      "\n",
      "[QUERY] What are the ingredients and effects of Crystal Soup from Zirconia?\n",
      "[ANSWER] Crystal Soup is made from ground luminous crystals and spiced with plasma herbs. Locals believe the soup enhances stamina and sharpens the senses.\n"
     ]
    }
   ],
   "source": [
    "# Example queries to test the pipeline\n",
    "queries = [\n",
    "    \"What led to the fall of the Kingdom of Eldoria?\",\n",
    "    \"How does the Starlink Quantum Drive create thrust?\",\n",
    "    \"What are the ingredients and effects of Crystal Soup from Zirconia?\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(\"\\n[QUERY]\", q)\n",
    "    result = rag_chain.invoke(q)\n",
    "    print(\"[ANSWER]\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d464bef",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Evaluate Generated Answers\n",
    "\n",
    "Evaluate RAG-generated answers against expected answers using multiple text metrics: Exact Match, ROUGE, BERTScore, BLEU, and METEOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba974fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "Query: What led to the fall of the Kingdom of Eldoria?\n",
      "Expected: The Kingdom of Eldoria fell due to internal strife, economic decline, and invasions by neighboring realms.\n",
      "Generated: The fall of Eldoria was caused by internal strife among rival noble houses, sparking decades of civil war, and the rise of the Great Shadow War, during which creatures of darkness invaded the borderlands. Additionally, the dragons, once allies, withdrew to their mountain strongholds, refusing to participate in the human conflict.\n",
      "Metrics:\n",
      "  exact_match: 0\n",
      "  rouge: {'rouge-1': {'r': 0.4375, 'p': 0.16279069767441862, 'f': 0.23728813164033327}, 'rouge-2': {'r': 0.06666666666666667, 'p': 0.02, 'f': 0.03076922721893532}, 'rouge-l': {'r': 0.375, 'p': 0.13953488372093023, 'f': 0.20338982655558752}}\n",
      "  bert_f1: 0.895494818687439\n",
      "  bleu: 0.010393938326032186\n",
      "  meteor: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): The fall of Eldoria was caused by internal strife among rival noble houses, sparking decades of civil war, and the rise of the Great Shadow War, during which creatures of darkness invaded the borderlands. Additionally, the dragons, once allies, withdrew to their mountain strongholds, refusing to participate in the human conflict.\n",
      "\n",
      "---\n",
      "Query: How does the Starlink Quantum Drive create thrust?\n",
      "Expected: The Starlink Quantum Drive generates thrust by manipulating quantum fields to produce directed energy propulsion.\n",
      "Generated: The Starlink Quantum Drive creates a localized warp bubble by manipulating entangled particles within the Quantum Resonance Chamber (QRC). Within this bubble, space contracts in front of the ship and expands behind it, propelling the craft forward without traditional thrust.\n",
      "Metrics:\n",
      "  exact_match: 0\n",
      "  rouge: {'rouge-1': {'r': 0.4666666666666667, 'p': 0.1891891891891892, 'f': 0.2692307651257397}, 'rouge-2': {'r': 0.2857142857142857, 'p': 0.10256410256410256, 'f': 0.15094339233891074}, 'rouge-l': {'r': 0.4666666666666667, 'p': 0.1891891891891892, 'f': 0.2692307651257397}}\n",
      "  bert_f1: 0.8980083465576172\n",
      "  bleu: 0.06839633481081311\n",
      "  meteor: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): The Starlink Quantum Drive creates a localized warp bubble by manipulating entangled particles within the Quantum Resonance Chamber (QRC). Within this bubble, space contracts in front of the ship and expands behind it, propelling the craft forward without traditional thrust.\n",
      "\n",
      "---\n",
      "Query: What are the ingredients and effects of Crystal Soup from Zirconia?\n",
      "Expected: Crystal Soup contains Zirconia crystals, moon herbs, and ethereal broth, granting temporary enhanced vision and clarity.\n",
      "Generated: The ingredients are ground luminous crystals and plasma herbs.\n",
      "\n",
      "The effects and properties are:\n",
      "*   The broth shines faintly in the dark.\n",
      "*   Plasma herbs produce tiny sparks when stirred.\n",
      "*   Locals believe it enhances stamina and sharpens the senses.\n",
      "Metrics:\n",
      "  exact_match: 0\n",
      "  rouge: {'rouge-1': {'r': 0.06666666666666667, 'p': 0.03125, 'f': 0.04255318714350429}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.06666666666666667, 'p': 0.03125, 'f': 0.04255318714350429}}\n",
      "  bert_f1: 0.8550627827644348\n",
      "  bleu: 0.005495155913866061\n",
      "  meteor: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): The ingredients are ground luminous crystals and plasma herbs.\n",
      "\n",
      "The effects and properties are:\n",
      "*   The broth shines faintly in the dark.\n",
      "*   Plasma herbs produce tiny sparks when stirred.\n",
      "*   Locals believe it enhances stamina and sharpens the senses.\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluate import evaluate_rag\n",
    "\n",
    "# Evaluation queries with expected answers\n",
    "eval_queries = [\n",
    "    {\n",
    "        \"query\": \"What led to the fall of the Kingdom of Eldoria?\",\n",
    "        \"expected_answer\": \"The Kingdom of Eldoria fell due to internal strife, economic decline, and invasions by neighboring realms.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How does the Starlink Quantum Drive create thrust?\",\n",
    "        \"expected_answer\": \"The Starlink Quantum Drive generates thrust by manipulating quantum fields to produce directed energy propulsion.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What are the ingredients and effects of Crystal Soup from Zirconia?\",\n",
    "        \"expected_answer\": \"Crystal Soup contains Zirconia crystals, moon herbs, and ethereal broth, granting temporary enhanced vision and clarity.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Evaluate RAG pipeline\n",
    "results = evaluate_rag(\n",
    "    rag_chain=rag_chain,\n",
    "    eval_queries=eval_queries,\n",
    "    metrics=[\"exact_match\", \"rouge\", \"bert\", \"bleu\", \"meteor\"]\n",
    ")\n",
    "\n",
    "# Display results for each query\n",
    "for r in results:\n",
    "    print(\"\\n---\")\n",
    "    print(f\"Query: {r['query']}\")\n",
    "    print(f\"Expected: {r['expected']}\")\n",
    "    print(f\"Generated: {r['generated']}\")\n",
    "    print(\"Metrics:\")\n",
    "    for metric, score in r[\"metrics\"].items():\n",
    "        print(f\"  {metric}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b8a475",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Evaluate Retriever Performance\n",
    "\n",
    "Check how well the retriever retrieves the correct documents using **Recall@k**, **Precision@k**, and **Mean Reciprocal Rank (MRR)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ff7f562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@3: 1.0\n",
      "Precision@3: 0.3333333333333333\n",
      "MRR: 1.0\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluate import recall_at_k, precision_at_k, mean_reciprocal_rank\n",
    "\n",
    "# True documents by source path for each query\n",
    "true_docs = [\n",
    "    [\"data/eldoria_history.pdf\"],\n",
    "    [\"data/quantum_drive_specs.pdf\"],\n",
    "    [\"data/zirconia_recipes.pdf\"]\n",
    "]\n",
    "\n",
    "# Predicted docs by retriever\n",
    "pred_docs = []\n",
    "for q in eval_queries:\n",
    "    retrieved = retriever.invoke(q[\"query\"])  # use invoke() instead of deprecated method\n",
    "    pred_docs.append([doc.metadata.get(\"source\") for doc in retrieved])\n",
    "\n",
    "# Compute retriever metrics\n",
    "print(\"Recall@3:\", recall_at_k(pred_docs, true_docs, k=3))\n",
    "print(\"Precision@3:\", precision_at_k(pred_docs, true_docs, k=3))\n",
    "print(\"MRR:\", mean_reciprocal_rank(pred_docs, true_docs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
